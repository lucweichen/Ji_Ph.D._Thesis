\chapter{Résumé Étendu}
\section*{Introduction}
Les \textit{workflows scientifiques} (\textit{SWfs}) permettent d'exprimer des activités de calcul à étapes multiples, \textit{p. ex.} charger les fichiers d'entrée, traiter les données, exécuter les analyses, et agréger les résultats. Les activités de calcul sont liées par des dépendances. Un SWf décrit les activités et les dépendances généralement sous forme de graphe, où les nœuds représentent les activités de calcul et les arêtes représentent les dépendances entre elles. Les SWfs sont largement utilisés dans plusieurs domaines, tels que l'astronomie \cite{Deelman2008}, la biologie \cite{Ocana2012}, la physique \cite{Ogasawara2011}, la sismologie \cite{Deelman2006z}, la météorologie \cite{Woitaszek2011}, et cetera. 

Les SWfs sont souvent \textit{orientés-données}, \textit{c.-à-d.} traitent, gèrent ou produisent d'énormes quantités de données. La gestion et la manipulation des SWfs orientés-données avec des outils traditionnels de programmation (\textit{p. ex.} des bibliothèques de code, des langages de script) devient très difficile à mesure que la complexité augmente. 
Par conséquent, les systèmes de gestion de workflows scientifiques (\textit{SWfMSs}) ont été spécialement mis au point afin de faciliter le traitement de SWfs, qui incluent de nombreux aspects tels que la modélisation, la programmation, le débogage, et l'exécution de SWfs. Les SWfMSs peuvent générer des données de provenance en cours d'exécution des SWfs. Les données de provenance, qui retracent l'exécution de SWfs et la relation entre les données d'entrée et les données de sortie, sont parfois plus importantes que l'exécution elle-même. Pour exécuter les SWfs orientés-données dans un délai raisonnable, les SWfMSs exploitent les techniques de parallélisme avec des ressources de calcul à haute performance (HPC) dans un environnement de cluster, grille ou cloud. Quelques SWfMSs existants, \textit{p. ex.}, Pegasus \cite{Deelman2005,Deelman2014}, Swift \cite{Zhao2007}, et Chiron \cite{Ogasawara2013}, sont accessibles au public pour l'exécution et la gestion de SWfs. Cependant, la plupart d'entre eux sont conçus pour les environnements de cluster ou grille. Dans les environnements de cloud, les SWfMSs utilisent généralement les mêmes approches conçues pour le calcul de clusters ou de grilles, qui ne sont pas optimisées pour les environnements de cloud.

En offrant des ressources quasi infinies, des services évolutifs et divers, la qualité de service stable et des politiques de paiement flexibles, le cloud devient une solution attractive pour l'exécution de SWfs. Les SWfMSs peuvent être facilement déployés dans le cloud en exploitant des Machines Virtuelles (VMs). Avec une méthode de pay-as-you-go, les utilisateurs de cloud n'ont pas besoin d'acheter des machines physiques et la maintenance des machines est assurée par les fournisseurs de cloud. Ainsi, les environnements de cloud deviennent les infrastructures intéressantes pour l'exécution de SWfs. 

Un cloud est typiquement \textit{multisite} (composé de plusieurs sites ou centres de données), avec chacun ses propres ressources et données et est explicitement accessible aux utilisateurs du cloud. En raison d'une faible latence et des problèmes de propriété, les données sont généralement stockées dans le site de cloud où sont localisées les sources de données. En conséquence, les données d'entrée d'un SWf peuvent être distribuées géographiquement. Par exemple, les données climatiques dans le système terrestre de grille \cite{Williams2009}, les grandes quantités de données brutes de la chromodynamique quantique (QCD) \cite{Perry2005} et les données du projet ALICE \cite{alice} sont distribuées géographiquement. Puisqu'un SWf peut traiter des données distribuées géographiquement, l'exécution de SWf doit être adaptée à un cloud multisite en exploitant les ressources de calcul ou de stockage distribuées au-delà d'un site de cloud. Les approches existantes restent limitées à des environments avec un seul cluster, dans une grille ou un cloud, et ne sont pas adaptées à un environnement multisite.

Cette thèse a été préparée dans le cadre de deux projets scientifiques: Z-CloudFlow (projet du centre MSR-Inria avec l'équipe Inria Kerdata) et MUSIC (projet FAPERJ-Inria avec des équipes de Rio de Janeiro) avec l'objectif principal d'exécuter efficacement les SWfs orientés-données dans un cloud multisite, où chaque site a son propre cluster, ses données et ses programmes. Cette thèse contient $5$ chapitres principaux: état de l'art, partitionnement de SWfs, provisionnement de VMs dans un seul site, ordonnancement multi-objectif de SWfs dans un cloud multisite et ordonnancement de tâches avec les données de provenance. Elle commence par un chapitre d'introduction et se termine par un chapitre de conclusion qui résume les contributions et propose des directions de recherche futures.

\section*{État de l'art} 

Un SWf est l'assemblage d'activités scientifiques de traitement de données avec des dépendances de données entre elles \cite{Deelman2009}.
Un SWfMS est un outil efficace pour exécuter les SWfs et gérer des ensembles de données dans différents environnements informatiques.
Afin d'exécuter un SWf dans un environnement donné, un SWfMS génère un plan d'exécution de workflow (WEP), qui est un programme qui saisit les décisions d'optimisation et les directives d'exécution, typiquement le résultat de la compilation et l'optimisation d'un workflow, avant l'exécution.
Cette section présente les techniques existantes de SWfs et SWfMSs, y compris l'architecture fonctionnelle, les techniques de parallélisation, l'analyse de  SWfMSs différents et l'environnement de cloud multisite.

L'architecture fonctionnelle d'un SWfMS peut être décrite en couches comme suit \cite{Deelman2005, Zhao2007, Altintas2004, Ogasawara2013}: présentation, services aux utilisateurs, génération de WEP, exécution de WEP et infrastructures. Un utilisateur interagit avec un SWfMS à travers la couche de présentation et réalise les fonctions souhaitées dans la couche de services aux utilisateurs. La couche de services d'utilisateur prend généralement en compte les données de provenance, qui sont les métadonnées qui capturent l'histoire de dérivation d'un ensemble de données. Un SWf est traité dans la couche de génération de WEP pour produire un WEP, qui est exécuté dans la couche d'exécution de WEP. Afin de réduire le temps d'exécution, les SWfs sont généralement exécutés en parallèle. Le SWfMS accède aux ressources physiques à travers la couche d'infrastructure pour l'exécution de SWfs.

L'exécution en parallèle de SWfs comprend le parallélisme et l'ordonnancement. Le parallélisme de SWfs identifie les tâches qui peuvent être exécutées en parallèle. Il y a deux niveaux de parallélisme: le parallélisme à gros grain et le parallélisme à grain fin.
Le parallélisme à gros grain, qui est effectué au niveau de SWf, est obtenu en exécutant des fragments de SWfs en parallèle. Un fragment de SWf (ou fragment pour faire court) peut être défini comme un sous-ensemble des activités et des dépendances de données d'un SWf original, qui est généré par le partitionnement de SWf. Le parallélisme à grain fin réalise le parallélisme en exécutant différentes activités en parallèle dans un SWf ou un fragment du SWf. L'ordonnancement de SWfs est un processus d'attribution de tâches aux ressources informatiques (\textit{c.-à-d.} nœuds de calcul) à exécuter \cite{Bux2013}. Les méthodes d'ordonnancement peuvent être statiques, dynamiques ou hybrides. L'ordonnancement statique génère un plan d'ordonnacement (SP) qui attribue toutes les tâches exécutables aux nœuds de calcul avant l'exécution et le SWfMS respecte strictement le SP pendant toute l'exécution de SWf \cite{Bux2013}. Il est efficace lorsque l'environnement d'exécution varie peu au cours de l'exécution de SWfs, et quand le SWfMS a suffisamment d'informations sur les capacités informatiques et de stockage des nœuds de calcul correspondants. L'ordonnancement dynamique produit des SPs qui distribuent les tâches exécutables aux nœuds de calcul lors de l'exécution de SWfs \cite{Bux2013}.
Ce type d'ordonnacement est approprié pour les SWfs dont la charge de travail des tâches est difficile à estimer, ou pour les environnements où les capacités des nœuds de calcul varient beaucoup pendant l'exécution. Les méthodes d'ordonnancement statiques et dynamiques ont leurs propres avantages. Elles peuvent être combinées en méthode d'ordonnacement hybride pour obtenir de meilleures performances.

Nous avons étudié huit SWfMSs typiques: Pegasus, Swift, Kepler, Taverna, Chiron, Galaxy, Triana \cite{Taylor2007}, Ascalon \cite{Fahringer2007}; ainsi que le portail de SWfMSs WS-PGRADE/gUSE \cite{Kacsuk2012}.
Pegasus et Swift ont un excellent soutien sur l'évolutivité et la haute performance de SWfs orientés-données.
Pegasus, Swift, Kepler, Taverna et WS-PGRADE/gUSE sont largement utilisés dans l'astronomie, la biologie, et cetera. Par contre, Galaxy ne peut exécuter que les SWfs bioinformatiques.
Tous les frameworks supportent le parallélisme à grain fin, l'ordonnancement dynamique et trois d'entre eux (Pegasus, Kepler et WS-PGRADE/gUSE) supportent l'ordonnancement statique. Tous ces systèmes supportent l'exécution de SWfs dans l'environnement de grille et de cloud.
Chiron exploite une approche algébrique \cite{Ozsu2011} pour gérer l'exécution en parallèle de SWfs orientés-données. 
Il utilise un modèle de données algébriques pour exprimer toutes les données comme les relations et représentent les activités de SWfs comme des expressions algébriques dans la couche de présentation.
Une relation contient des ensembles de tuples composés d'attributs de base.
Une expression algébrique consiste en activités algébriques, opérandes supplémentaires, opérateurs et relations d'entrée et de sortie.
Une activité algébrique contient un programme ou une expression SQL, et les schémas de relations d'entrée et de sortie.
Un opérande supplémentaire est l'information latérale pour l'expression algébrique, qui peut être une relation ou un ensemble d'attributs de regroupement.
Il y a six opérateurs qui peuvent automatiquement transformer une activité en de multiples tâches à exécuter.

Il y a des cas importants où les SWfs devront être exécutés sur plusieurs sites de cloud, \textit{p. ex.} parce que les données accessibles par le SWf sont dans les bases de données de différents groupes de recherche dans les différents sites ou parce que l'exécution d'un SWf a besoin de plus de ressources que celles d'un seul site. Les grands fournisseurs de cloud tels que Microsoft et Amazon ont généralement plusieurs centres de données distribués géographiquement dans les différents sites.
Dans un cloud multisite, nous pouvons exécuter un SWf avec le parallélisme à grain fin ou le parallélisme à gros grain au niveau multisite.
L'exécution de SWfs avec le parallélisme à grain fin est d'attribuer toutes les tâches dans chaque site de cloud.
Bien qu'il existe des méthodes d'ordonnancement \cite{Duan2014, Ostermann2009a}, elles n'ont pas de support à la gestion des données de provenance, celles qui sont importantes pour l'exécution de SWfs.
Avec le parallélisme à gros grain, un SWf est partitionné en fragments. Chaque fragment est affecté à un site spécifique et ses tâches sont allouées dans les VMs de ce site.
Certaines méthodes \cite{Chen2012a, Chen2013} sont proposées pour permettre d'exécuter les SWfs dans un cloud multisite par le partitionnement de SWfs, ils se concentrent généralement sur un seul objectif, \textit{c.-à-d.} la réduction du temps d'exécution, avec une contrainte de stockage mais le cas multi-objectif reste un problème, \textit{p. ex.} réduire à la fois le temps d'exécution et le coût monétaire. En outre, ils n'ont généralement pas de support pour le provisionnement dynamique de VMs dans le cloud, ce qui est essentiel pour l'exécution dans un environnement de cloud.
Chiron est adapté au cloud grâce à son extension, Scicumulus \cite{Oliveira2010, Oliveira2012}, qui supporte le provisionnement de calcul dynamique \cite{Oliveira2012a}. Cependant, cette approche se concentre sur un environnement de cloud mono site.

\section*{Partitionnement de SWfs}
Nous attaquons le problème de partitionnement de SWfs afin d'exécuter les SWfs dans un cloud multisite. Notre objectif principal est de permettre l'exécution de SWfs dans un cloud multisite pour partitionner les SWfs en fragments afin de réduire le temps d'exécution, tout en assurant que certaines activités soient exécutées sur les sites de cloud spécifiques.

Il y a essentiellement deux techniques de partitionnement de SWfs, \textit{c.-à-d.} le partitionnement de DAG et le partitionnement de données. Le partitionnement de DAG transforme un DAG composé des activités en un DAG composé des fragments tandis que chaque fragment est un DAG composé des activités et des dépendances.
Le partitionnement de données divise les données d'entrée d'un fragment généré par le partitionnement de DAG en plusieurs ensembles de données, dont chacun est encapsulé dans un fragment nouvellement généré. Nous nous concentrons sur le partitionnement de DAG dans ce travail. Il y a une technique de partitionnement général, \textit{c.-à-d.} l'encapsulation des activités, qui encapsule chaque activité dans un fragment de SWf.

Nous proposons trois méthodes de partitionnement de SWfs, \textit{c.-à-d.} la  confidentialité scientifique (SPr), la minimisation de la transmission de données (DTM) et l'adaptation de la capacité informatique (CCA). SPr partitionne les SWfs en mettant les activités de blocage et ses activités suivantes disponibles à un fragment, pour mieux supporter la surveillance de l'exécution sous la contrainte de sécurité. DTM partitionne les SWfs avec la prise en compte des activités de blocage, tout en minimisant le volume de données à transférer entre les fragments de SWfs différents. CCA partitionne les SWfs selon la capacité de calcul de différents sites de cloud. Cette technique tente de mettre plus d'activités au fragment à exécuter dans un site de cloud avec une plus grande capacité de calcul.
Nos techniques de partitionnement sont adaptées aux différentes configurations de cloud afin de réduire le temps d'exécution des SWfs. De plus, nous  proposons également d'utiliser des techniques de raffinage de données, \textit{c.-à-d.} la combinaison de fichiers et la compression de données, afin de réduire le temps de la transmission de données entre les différents sites.

Nous prenons Buzz SWf \cite{Dias2013} comme un cas d'utilisation et adaptons Chiron pour l'exécution de SWfs dans le cloud multisite. Nous évaluons largement nos techniques de partitionnement proposées en exécutant Buzz avec Chiron déployé dans deux sites, \textit{c.-à-d.} Europe occidentale et l'Est des États-Unis, du cloud Azure.
Nous considérons deux configurations de cloud: homogène et hétérogène. Le cas où tous les sites ont les mêmes nombres et types de VMs correspond à la configuration homogène tandis que dans une configuration hétérogène les sites ont des nombres ou types de VMs différents. Les résultats de nos expérimentations montrent que DTM avec des techniques de raffinage de données est adapté ($24,1$\% du temps épargné par rapport à ACC sans raffinage de données) à exécuter les SWfs dans un cloud multisite avec une configuration homogène, et qu'ACC fonctionne mieux ($28,4$\% du temps épargné par rapport à la technique SPr sans raffinage de données) avec une configuration hétérogène. En outre, les résultats montrent que les techniques de raffinage de données peuvent réduire considérablement le temps de la transmission de données entre deux sites différents.

\section*{Provisionnement de VMs dans un site}
Nous traitons le problème de la génération de plans de provisionnement de VMs pour l'exécution de SWfs dans un seul site de cloud pour plusieurs objectifs. Notre principale contribution est de proposer un modèle de coût et un algorithme afin de générer des plans de provisionnement de VMs pour réduire à la fois le temps d'exécution et le coût monétaire pour l'exécution de SWfs dans un seul site de cloud.

Pour résoudre le problème, nous concevons un modèle de coût multi-objectif pour l'exécution de SWfs dans un seul site de cloud. Le modèle de coût est une fonction pondérée avec les objectifs de réduction du temps d'exécution et le coût monétaire basé sur le temps d'exécution et le coût monétaire souhaité par les utilisateurs. L'importance de l'objectif du temps d'exécution doit être supérieure à zéro et inférieure à $1$, \textit{p. ex.} $0.1$ ou $0.9$. Notre modèle de coût considère la charge de travail séquentiel et le coût pour démarrer les VMs, qui est plus précis par rapport aux modèles de coûts existants, \textit{p. ex.} GraspCC \cite{Coutinho2014}. Le temps d'exécution estimé est basé sur la loi d'Amdahl \cite{Sun2013}. Le coût monétaire estimé est basé sur le temps d'exécution estimé et le coût monétaire pour utiliser des VMs dans une unité de temps.

En nous appuyant sur le modèle de coût, nous proposons un algorithme de provisionnement dans un seul site (SSVP) pour générer des plans de provisionnement à exécuter les SWfs dans un seul site de cloud. SSVP calcule d'abord un nombre optimal de cœurs de processeurs pour l'exécution de SWfs basé sur le modèle de coût multi-objectif. Ensuite, il génère un plan de provisionnement et améliore itérativement le plan de provisionnement afin de réduire le coût basé sur le modèle de coût et le nombre optimal de cœurs de processeurs. Enfin, SSVP génère un plan de provisionnement de VMs correspondant au coût minimum pour exécuter les SWfs avec l'importance spécifique de chaque objectif.

Nous avons réalisé des évaluations approfondies à comparer notre modèle de coût et celui de GraspCC. Nous avons exécuté le workflow SciEvol \cite{Ocana2012} avec différentes quantités de données d'entrée et de différentes importance du temps d'exécution, en déployant Chiron dans le site de l'Est du Japon du cloud d'Azure. Les résultats des expérimentations montrent que notre algorithme peut adapter les plans de provisionnement de VMs aux différentes configurations, \textit{c.-à-d.} générer différents plans de provisionnement de VMs pour les différentes importances du temps d'exécution. SSVP génère de meilleurs plans de provisionnement ($53,6\%$) par rapport à GraspCC. Les résultats révèlent également que notre modèle de coût est plus ($76,7\%$) précis pour estimer le temps d'exécution et le coût monétaire par rapport à GraspCC, en raison de la prise en compte de la charge de travail séquentiel et le coût pour démarrer les VMs.

\section*{Ordonnancement multi-objectif de SWfs dans un cloud multisite}
Nous résolvons le problème de l'ordonnancement des fragments de SWfs avec plusieurs objectifs, afin de permettre l'exécution de SWfs dans un cloud multisite avec une contrainte de données stockées. Nous imaginons que les données stockées dans un site spécifique ne peuvent pas être autorisées à être transférées vers d'autres sites en raison de la propriété ou grandes quantités de données, qui s'appelle la contrainte de données stockées. Dans ce travail, nous avons pris en compte les différents prix des VMs et les données stockées dans des sites différents.

Le modèle de coût multisite est une fonction pondérée composée du temps d'exécution et du coût monétaire basé sur le temps d'exécution et le coût monétaire souhaité par l'utilisateur. Toutefois, puisqu'il est difficile d'estimer le temps d'exécution et le coût monétaire globale pour exécuter un SWf dans un cloud multisite, nous proposons un modèle de coût multisite comme une combinaison du coût pour exécuter chaque fragment du SWf. Nous décomposons également le temps d'exécution et le coût monétaire souhaité d'un SWf en une combinasion de ceux de chaque fragment du SWf. Basé sur le temps d'exécution et le coût monétaire souhaité de chaque fragment du SWf, on peut estimer le coût pour exécuter chaque fragment du SWf sur un site prévu basé sur le modèle de coût correspondant à SSVP. Enfin, notre modèle de coût multisite peut estimer le coût global en considérant le coût à transférer des données à travers différents sites avec un plan d'ordonnancement.

Nous présentons deux algorithmes d'ordonnancement que nous avons adaptés, l'ordonnancement basé sur les localisations de données (LocBased) et l'ordonnancement gourmand de sites (SGreedy), et l'algorithme que nous proposons: l'ordonnancement gourmand des activités (ActGreedy). LocBased exploite DTM à partitionner les SWfs et attribue les fragments aux sites où les données d'entrée sont stockées. Cet algorithme ignore le coût monétaire et peut encourir un coût énorme à exécuter les SWfs. SGreedy prend l'avantage de la technique d'encapsulation des activités pour partitionner les SWfs et attribue le meilleur fragment à chaque site. Il attribue les activités d'un pipeline des activités aux sites différents, qui conduit à une grande transmission de données intersite et un temps d'exécution plus long. ActGreedy partitionne les SWfs avec la technique d'encapsulation des activités et regroupe de petits fragments en plus gros fragments pour réduire la transmission de données entre les différents sites et attribue chaque fragment au meilleur site. Cet algorithme permet de réduire le temps d'exécution global en comparant le coût pour exécuter des fragments dans chaque site, qui est généré basé sur SSVP.
 
Nous avons évalué notre algorithme d'ordonnancement en exécutant SciEvol avec différentes quantités de données d'entrée et les différentes importances des objectifs dans trois sites du cloud d'Azure. Les trois sites de cloud sont l'Ouest de l'Europe, l'Ouest du Japon, et l'Orient du Japon et les coûts d'utilisation de VMs sur chaque site sont différents. Nous avons utilisé SSVP pour générer des plans de provisionnement de VMs et Chiron pour exécuter des fragments du SWf dans chaque site.
Les résultats des expérimentations montrent qu'ActGreedy fonctionne mieux en termes du coût pondéré pour exécuter les SWfs dans un cloud multisite par rapport à LocBased (jusqu'à $10.7\%$) et SGreedy (jusqu'à $17,2\%$). En outre, les résultats révèlent également que le temps d'ordonnancement d'ActGreedy est raisonnable par rapport aux deux approches générales, \textit{c.-à-d.} Brut Force et Genetic.

\section*{Ordonnancement de tâches avec les données de provenance}
Nous traitons le problème d'ordonnancement de tâches pour l'exécution de SWfs en multisite avec le soutien sur les données de provenance. L'objectif principal est de permettre l'exécution de SWfs avec les données d'entrée distribuées dans les différents sites dans un délai minimum avec le soutien sur les données de provenance, tandis que les bandes passantes entre les différents sites sont différentes. Dans ce travail, nous proposons Chiron Multisite et un algorithme d'ordonnancement de tâches.

Chiron Multisite est une extension de Chiron pour les environnements de cloud multisite. Chiron met en œuvre une approche algébrique pour exprimer les SWfs et optimiser l'exécution de SWfs dans un seul site. Chiron Multisite permet d'exécuter simultanément des tâches d'une activité sur des sites différents pour traiter les données distribuées. Nous proposons aussi le modèle de provenance multisite pour  Chiron Multisite. Dans un cloud multisite, nous proposons différentes méthodes pour le transfert de données intersite. Nous utilisons notre méthode d'ordonnancement à deux niveaux, \textit{c.-à-d.} l'ordonnancement multisite et l'ordonnancement d'un seul site, pour l'ordonnancement de tâches dans un cloud multisite. Multisite Chiron correspond au parallélisme à grain fin au niveau multisite, qui permet aux différentes tâches d'un fragment d'être exécutées dans les différents sites de cloud.

Nous proposons un algorithme de l'ordonnancement multisite de tâches orientés-données (DIM) pour attribuer des tâches au niveau multisite en considérant le support des données de provenance, différentes bandes passantes entre les différents sites et la distribution de données d'entrée. D'abord, DIM attribue les tâches en fonction de localisations de données sur différents sites. Puis, il redistribue les tâches afin d'atteindre l'équilibre de charge entre les différents sites de cloud basés sur un modèle de coût pour estimer la charge d'exécution de chaque site. L'équilibre de charge représente qu'il faut exécuter les tâches dans le même temps dans chaque site. Le modèle de coût prend en compte le temps de transférer les données d'entrée des tâches entre les différents sites et le temps de transférer les données de provenance à une base de données centralisée.

Nous avons évalué nos algorithmes avec Chiron Multisite en exécutant Buzz et Montage \cite{Montage} dans trois sites de cloud Azure, \textit{c.-à-d.} US centrale, l'Ouest de l'Europe et le Nord de l'Europe. Nous avons exécuté buzz avec différentes quantités de données d'entrée et Montage avec différents degrés en utilisant le Chiron Multisite. Les résultats expérimentaux montrent que DIM est beaucoup mieux que deux algorithmes d'ordonnancement existants, \textit{c.-à-d.} MCT (jusqu'à $24,3\%$) et OLB (jusqu'à $49,6\%$), en termes du temps d'exécution. DIM peut également réduire de manière significative (jusqu'à plus de $7$ fois) les données transférées entre les sites, comparé avec MCT et OLB. En outre, les résultats révèlent également que le temps d'ordonnancement de DIM est raisonnable par rapport à la durée d'exécution globale de SWfs (moins de  $3\%$). En particulier, les expérimentations montrent que la distribution de tâches est adaptée en fonction de différentes bandes passantes entre les différents sites pour la génération de données de provenance.

\section*{Conclusion}

Dans cette thèse, nous avons traité le problème de l'exécution de SWfs orientés-données dans un cloud multisite, où les données et les ressources informatiques peuvent être distribués aux différents sites de cloud.
Pour cette raison, nous avons proposé une approche distribuée et parallèle qui exploite les ressources disponibles dans les différents sites de cloud.
Dans notre étude de l'état de l'art, nous avons proposé une architecture fonctionnelle de SWfMS en analysant et en catégorisant les techniques existantes.
Pour exploiter le parallélisme, nous avons utilisé une approche algébrique, ce qui permet d'exprimer les activités de SWfs en utilisant des opérateurs à automatiquement les transformer en de multiples tâches.
Nous avons proposé l'algorithmes de partitionnement de SWfs, un algorithme dynamique de provisionnement de SWfs dans un seul site, un algorithme d'ordonnancement multi-objectif dans un cloud multisite, un algorithme d'ordonnancement de tâches avec les données de provenance et Chiron Multisite.
Différents algorithmes de partitionnement de SWfs partitionnent un SWf à plusieurs fragments.
L'algorithme de provisionnement de VMs est utilisé pour créer dynamiquement une combinaison optimale de VMs pour exécuter des fragments d'un SWf dans chaque site de cloud.
L'algorithme d'ordonnancement multi-objectif distribue les fragments d'un SWf aux sites de cloud avec le coût minimum basé sur un modèle de coût multi-objectif.
L'algorithme d'ordonnancement de tâches distribue directement des tâches entre les différents sites de cloud tout en réalisant l'équilibrage de charge au niveau de chaque site basé sur un SWfMS multisite, Chiron Multisite.
Chiron Multisite est une extension de Chiron pour exécuter les SWfs dans les environnements de cloud multisite.
Nous avons évalué nos solutions proposées en exécutant des SWfs réels dans le cloud de Microsoft Azure. Nos résultats expérimentaux montrent les avantages de nos solutions par rapport aux techniques existantes.

Nos contributions peuvent être utilisées comme le point de départ pour la recherche future. Nous proposons les futures directions de recherche suivantes:
\begin{itemize}
\item \textbf{Distribution de la provenance}. La gestion de données de provenance distribuées peut réduire le temps de générer ou de récupérer des données de provenance dans chaque site afin de réduire le temps d'exécution global de SWfs dans un cloud multisite.
\item \textbf{Transfert de données}. Une solution possible de transférer efficacement des données entre deux sites de cloud est de sélectionner plusieurs nœuds sur chaque site pour envoyer ou recevoir des données, en exploitant le transfert de données en parallèle et en faisant le transfert de données plus efficace.
\item \textbf{Spark multisite}. Nos algorithmes et optimisations d'ordonnancement multisite pourraient être adaptées pour le framework Spark pour l'exécution de SWfs dans un cloud multisite.
\item \textbf{Architecture}: Une architecture peer-to-peer peut être utilisée pour atteindre la tolérance aux pannes lors de l'exécution de SWfs dans un seul site de cloud ou un cloud multisite.
\item \textbf{Ordonnancement dynamique}. L'ordonnancement dynamique des activités ou des tâches peut être mieux adapté à l'environnement d'exécution en considérant les paramètres mesurés lors de l'exécution de SWfs, \textit{p. ex.} le coût monétaire des VMs, la bande passante pour transferer ou recevoir des données dans les VMs, etc.
\end{itemize}

\section*{Publications}
Les contributions ont conduit aux publications suivantes:

\begin{itemize}

\item \textit{Ji Liu}, Esther Pacitti, Patrick Valduriez, Daniel de Oliveira and Marta Mattoso. Multi-Objective Scheduling of Scientific Workflows in Multisite Clouds. Dans BDA’ $2016$: Gestion de données - principles, technologies et applications, $2016$. À paraître.

\item Luis Pineda-Morales, \textit{Ji Liu}, Alexandru Costan, Esther Pacitti, Gabriel Antoniu, Patrick Valduriez, and Marta Mattoso. Managing Hot Metadata for Scientific Workflows on Multisite Clouds. Dans IEEE International Conference on Big Data, $2016$. À paraître.

\item \textit{Ji Liu}, Esther Pacitti, Patrick Valduriez, Marta Mattoso. Scientific Workflow Scheduling with Provenance Support in Multisite Cloud. Dans 12th International Meeting on High Performance Computing for Computational Science (VECPAR), $2016$, $1-8$.

\item \textit{Ji Liu}, Esther Pacitti, Patrick Valduriez, Daniel Oliveira, Marta Mattoso. Multi-objective scheduling of Scientific Workflows in multisite clouds. Dans Future Generation Computer Systems, $2016$, volume $63$, $76-95$.

\item \textit{Ji Liu}, Esther Pacitti, Patrick Valduriez, Marta Mattoso. A Survey of Data-Intensive Scientific Workflow Management. Dans Journal of Grid Computing, $2015$, volume $13$, numéro $4$, $457-493$.

\item \textit{Ji Liu}, Esther Pacitti, Patrick Valduriez, Marta Mattoso, Parallelization of Scientific Workflows in the Cloud, Rapport de recherche RR-$8565$, $2014$.

\item \textit{Ji Liu}, V\'{i}tor Silva, Esther Pacitti, Patrick Valduriez, Marta Mattoso. Scientific Workflow Partitioning in Multi-site Clouds. Dans BigDataCloud'2014: 3rd Workshop on Big Data Management in Clouds in conjunction with Euro-Par, $2014$. Springer, Lecture Notes in Computer Science, $8805$,  $105-116$.

\item \textit{Ji Liu}. Multisite Management of Data-intensive Scientific Workflows in the Cloud. Dans BDA’$2014$: Gestion de données - principles, technologies et applications, $2014$, $28-30$.

\end{itemize}
